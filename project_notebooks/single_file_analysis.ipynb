{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predominant pitch extraction in polyphonic signals\n",
    "\n",
    "This notebook shows the process of a single audio file of the dataset, here are the sections:\n",
    "\n",
    "1. [Preparing the audio file](#preparing_audio_file)\n",
    "2. [Multi Pitch Detection (MPD)](#mpd)\n",
    "3. [Multi-Pitch Trajectory (MPTC)](#mptc)\n",
    "4. [Trajectory Segmentation](#trajectory_segmentation)\n",
    "5. [Showing the results](#showing_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'project_notebooks'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-90da139d9d2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'..'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_func\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mROOT_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'project_notebooks'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/utils/eval_func.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstants\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/utils/constants.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'..'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mROOT_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'project_notebooks'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mDATASET_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mROOT_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'adc2004_full_set'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'project_notebooks'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import essentia as ess\n",
    "import essentia.standard as estd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import IPython.display as ipd\n",
    "from scipy import signal\n",
    "\n",
    "eps = np.finfo(float).eps\n",
    "\n",
    "os.chdir('..')\n",
    "from utils.eval_func import *\n",
    "ROOT_PATH = os.getcwd()\n",
    "os.chdir('project_notebooks')\n",
    "\n",
    "SAMPLE_RATE = 44100 # Sample rate\n",
    "ANALYZE_SOUND_FRAME_SIZE = 2048 # Surce sound analysis frame sizes\n",
    "HOP_SIZE = 256 # Parameter used by the \"FrameGenerator\" and \"FFT\" functions\n",
    "\n",
    "DATASET_PATH = os.path.join(ROOT_PATH,'data','adc2004_full_set')\n",
    "\n",
    "OUTPUT_PLOT_FOLDER = \"plots\"\n",
    "\n",
    "if not os.path.isdir(OUTPUT_PLOT_FOLDER): os.makedirs(OUTPUT_PLOT_FOLDER)\n",
    "\n",
    "filename = 'daisy1' + '.wav'\n",
    "audio_path = os.path.join(DATASET_PATH, 'wav', filename)\n",
    "\n",
    "params = {\n",
    "            \"text.color\" : \"w\",\n",
    "            \"ytick.color\" : \"w\",\n",
    "            \"xtick.color\" : \"w\",\n",
    "            \"axes.labelcolor\" : \"w\",\n",
    "            \"axes.edgecolor\" : \"w\",\n",
    "            \"axes.facecolor\" : '2e353e'\n",
    "        }\n",
    "plt.rcParams.update(params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the audio file\n",
    "<a id=\"preparing_audio_file\"></a>\n",
    "\n",
    "Only one single file is loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Loading the audio file and applying an equal loudness filter\n",
    "audio = estd.EqloudLoader(filename = audio_path, sampleRate = SAMPLE_RATE)()\n",
    "\n",
    "# Extracting the predominant pitch with Essentia for reference purposes\n",
    "pitch, confidence = estd.PredominantPitchMelodia(\n",
    "    frameSize = ANALYZE_SOUND_FRAME_SIZE, \n",
    "    hopSize = HOP_SIZE\n",
    ")(audio)\n",
    "\n",
    "# Plotting original audio file\n",
    "fig = plt.figure(figsize=(14, 8))\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax1.set_title('Raw wave of ' + filename)\n",
    "ax1.set_ylabel('Amplitude')\n",
    "ax1.plot(audio)\n",
    "\n",
    "# Plotting predominant pitch\n",
    "ax2 = fig.add_subplot(212)\n",
    "ax2.grid(b = True, axis = 'both', color = 'w', linestyle = '-', linewidth = 0.3)\n",
    "ax2.plot(pitch)\n",
    "ax2.set_title('Pitch reference of ' + filename)\n",
    "ax2.set_ylabel('Freqs in Hz')\n",
    "ax2.set_xlabel('Seconds')\n",
    "\n",
    "# Saving the plots\n",
    "plt.savefig(OUTPUT_PLOT_FOLDER + \"/reference.png\", transparent = True)\n",
    "\n",
    "# Showing the object to play the file\n",
    "ipd.display(ipd.Audio(audio, rate=44100))\n",
    "\n",
    "# Showing the plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Pitch Detection (MPD)\n",
    "<a id=\"mpd\"></a>\n",
    "\n",
    "- Autocorrelation Based\n",
    "- All possible maxima of the autocorrelation are considered\n",
    "- List of frequencies for each frame sorted by the probability of them of being the predominant pitch in that time frame \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocorrelation(x_win, fs, minF0 = 100,maxF0 = 1000):\n",
    "    '''F0 detection on a single frame using autocorrelation\n",
    "    Parameters\n",
    "    ----------\n",
    "    x_win : numpy.array\n",
    "        Windowed signal frame\n",
    "    fs,minF0,maxF0 : int\n",
    "        Sampling rate, minimum and maximum F0 limits\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    ValAC : numpy.array\n",
    "    f0 : numpy.array\n",
    "        Estimated f0 and autocorrelation values for those f0\n",
    "    ''' \n",
    "    f0 = np.array([])\n",
    "    minT0 = int(fs/maxF0)\n",
    "    maxT0 = int(fs/minF0)\n",
    "\n",
    "    Ts = range(minT0,maxT0)\n",
    "    ValAC = np.array([])\n",
    "    for k in Ts:\n",
    "        x_win_shifted = np.hstack((np.zeros(k),x_win[:-k]))\n",
    "        autoCorr = np.dot(x_win,x_win_shifted)\n",
    "        ValAC = np.append(ValAC, autoCorr)\n",
    "        \n",
    "    f0 = np.divide(fs*np.ones(len(Ts)),Ts)\n",
    "    return ValAC, f0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mpd(audio, frameSize = ANALYZE_SOUND_FRAME_SIZE, hopSize = HOP_SIZE):\n",
    "    '''Computes the Multi Pitch Detection (MPD) algorithm for the given signal\n",
    "    Parameters\n",
    "    ----------\n",
    "    audio : numpy.array\n",
    "        Audio file\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    frame_freq : numpy.array\n",
    "        List of sorted frequencies by relevance for each frame\n",
    "    ''' \n",
    "    \n",
    "    # Getting the window\n",
    "    window = estd.Windowing()\n",
    "\n",
    "    # List of frequencies for each frame in a list\n",
    "    frame_freq = []\n",
    "    \n",
    "    # For each frame in the audio file\n",
    "    for frame in estd.FrameGenerator(audio, frameSize = frameSize, hopSize = hopSize):\n",
    "        \n",
    "        framelist = []\n",
    "        frame_win = window(frame)\n",
    "        \n",
    "        # Computing the autocorrelation\n",
    "        AC, f0 = autocorrelation(frame_win, SAMPLE_RATE)\n",
    "        AC = AC/max(AC)\n",
    "        \n",
    "        # Getting the peaks\n",
    "        peaks,_ = signal.find_peaks(AC)\n",
    "\n",
    "        tuplelist = [(a,b) for a,b in zip(f0[peaks],AC[peaks])]\n",
    "        tuplelist.sort(key = lambda x: x[1], reverse = True)\n",
    "\n",
    "        framelist = [a for a,b in tuplelist]\n",
    "\n",
    "        frame_freq.append(framelist)\n",
    "        \n",
    "    # Returning the value\n",
    "    return frame_freq\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the Multi Pitch Detection (MPD) algorithm\n",
    "audio_multi_pitch = mpd(audio)\n",
    "\n",
    "# Creating an array for the most likely frequency for each frame\n",
    "most_likely = [frame[0] for frame in audio_multi_pitch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting original audio file\n",
    "fig = plt.figure(figsize=(14, 8))\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax1.grid(b = True, axis = 'both', color = 'w', linestyle = '-', linewidth = 0.3)\n",
    "ax1.set_title('Pitch prediction of ' + filename)\n",
    "ax1.set_ylabel('Freqs in Hz')\n",
    "ax1.plot(most_likely)\n",
    "\n",
    "# Plotting predominant pitch\n",
    "ax2 = fig.add_subplot(212)\n",
    "ax2.grid(b = True, axis = 'both', color = 'w', linestyle = '-', linewidth = 0.3)\n",
    "ax2.plot(pitch)\n",
    "ax2.set_title('Essentia pitch reference of ' + filename)\n",
    "ax2.set_ylabel('Freqs in Hz')\n",
    "ax2.set_xlabel('Frames')\n",
    "\n",
    "# Saving the plots\n",
    "plt.savefig(OUTPUT_PLOT_FOLDER + \"/mpd.png\", transparent = True)\n",
    "\n",
    "# Showing the object to play the file\n",
    "ipd.display(ipd.Audio(audio, rate=44100))\n",
    "\n",
    "# Showing the plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Pitch Trajectory (MPTC)\n",
    "<a id=\"mptc\"></a>\n",
    "\n",
    "- Still in progress\n",
    "- For now, the pitch with the best autocorrelation in each frame is used.\n",
    "- In the future, octave correction between frames and harmonic correction in the same frame will be implemented here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMostLikely(freq_mat):\n",
    "    return [frame[0] for frame in freq_mat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def octaveCorrection(freq_arr, tol_percent = 1):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    if tol_percent > 100: raise ValueError(\"tol_percent music be 0 < tol_percent <= 100\")\n",
    "    elif tol_percent <= 0 : raise ValueError(\"tol_percent music be 0 < tol_percent <= 100\")\n",
    "    \n",
    "    distance = 1\n",
    "    octave_ratio = 2\n",
    "    inverse_octave_ratio = 1/octave_ratio\n",
    "    tolerance = tol_percent/100\n",
    "    \n",
    "    for i,freq in enumerate(freq_arr):\n",
    "        if i < len(freq_arr)-1:\n",
    "            ratio = freq/freq_arr[i+1]\n",
    "            if (1-tolerance)*octave_ratio < ratio < (1+tolerance)*octave_ratio:\n",
    "                freq_arr[i+1] = 2 * freq_arr[i+1]\n",
    "            elif (1-tolerance)*inverse_octave_ratio < ratio < (1+tolerance)*inverse_octave_ratio:\n",
    "                freq_arr[i+1] = freq_arr[i+1] / 2\n",
    "            \n",
    "    \"\"\"\n",
    "    threshold = 0.02\n",
    "    octave_ratio = 2\n",
    "    \n",
    "    for i,freq in enumerate(freq_arr):\n",
    "        \n",
    "        if  5 < i < (len(freq_arr) - 3):\n",
    "            \n",
    "            freq_aux_arr = np.round(freq_arr[i-5:i+3]).astype(int)\n",
    "            first_condition = freq_aux_arr != int(np.round(freq))\n",
    "            second_condition = freq_aux_arr != int(np.round(freq_arr[i-1]))\n",
    "            #freq_aux_arr[first_condition & second_condition] = 0\n",
    "            \n",
    "            #freq_aux_arr = [item for item in freq_aux_arr if not (first_condition & second_condition)]\n",
    "            freq_aux_arr = [item for item in freq_aux_arr\n",
    "                if (item==int(np.round(freq))) or (item==int(np.round(freq)))]\n",
    "            \n",
    "            prev_ratio = freq / freq_arr[i-1]\n",
    "            current_ratio = 1 / prev_ratio\n",
    "            \n",
    "            if (octave_ratio - threshold) < prev_ratio < (octave_ratio + threshold):\n",
    "                most_ocurrent = np.argmax(np.bincount(freq_aux_arr))\n",
    "                \n",
    "                if abs(most_ocurrent-freq_arr[i-1]) < abs(most_ocurrent-freq):\n",
    "                    freq_arr[i] = freq_arr[i] / 2\n",
    "                \n",
    "            if (octave_ratio - threshold) < current_ratio < (octave_ratio + threshold):\n",
    "                most_ocurrent = np.argmax(np.bincount(freq_aux_arr))\n",
    "                \n",
    "                if abs(most_ocurrent-freq_arr[i-1]) < abs(most_ocurrent-freq):\n",
    "                    #print(\"PRE\")\n",
    "                    #print(\"freq_arr[i]\", freq_arr[i])\n",
    "                    #print(\"freq_arr[i] * 2: \", freq_arr[i] * 2)\n",
    "                    freq_arr[i] = freq_arr[i] * 2\n",
    "                    #print(\"freq_arr[i]\", freq_arr[i])\n",
    "                    #print(\"POST\")\n",
    "    \"\"\"\n",
    "    return freq_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def framesReduction(audio_multi_pitch):\n",
    "    for i,frame in enumerate(audio_multi_pitch):\n",
    "        upper = min(3,len(frame))\n",
    "        audio_multi_pitch[i] = frame[:upper]\n",
    "    \n",
    "    return audio_multi_pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mptc(audio_multi_pitch):\n",
    "    '''Computes the Multi Pitch Trajection (MPTC) algorithm for the given signal\n",
    "    Parameters\n",
    "    ----------\n",
    "    audio_multi_pitch : numpy.array\n",
    "        List of sorted frequencies by relevance for each frame\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    freq_arr : numpy.array\n",
    "        Corrected pitch trajectory\n",
    "    ''' \n",
    "    \n",
    "    # FRAME LENGTH REDUCTION\n",
    "    audio_multi_pitch = framesReduction(audio_multi_pitch)\n",
    "    \n",
    "    # HARMONIC DELETION PER FRAME\n",
    "    #audio_multi_pitch = harmonicDeletion(audio_multi_pitch)\n",
    "    \n",
    "    #GET THE MOST LIKELY FREQUENCY VALUE\n",
    "    most_likely_freq_arr = getMostLikely(audio_multi_pitch)\n",
    "    \n",
    "    original_freq_arr = most_likely_freq_arr.copy()\n",
    "    \n",
    "    fig = plt.figure(figsize=(14, 10))\n",
    "    ax1 = fig.add_subplot(311)\n",
    "    ax1.grid(b = True, axis = 'both', color = 'w', linestyle = '-', linewidth = 0.3)\n",
    "    ax1.set_title('original_freq_arr')\n",
    "    ax1.set_ylabel('Freqs in Hz')\n",
    "    ax1.plot(original_freq_arr)\n",
    "    #ax1.stem(original_freq_arr[2300:2400])\n",
    "    \n",
    "    # OCTAVE CORRECTION\n",
    "    freq_arr = octaveCorrection(most_likely_freq_arr)\n",
    "    \n",
    "    print(\"Are equal? \", np.array_equiv(original_freq_arr, freq_arr))\n",
    "    \n",
    "    ax2 = fig.add_subplot(312)\n",
    "    ax2.grid(b = True, axis = 'both', color = 'w', linestyle = '-', linewidth = 0.3)\n",
    "    ax2.set_title('freq_arr_mod')\n",
    "    ax2.set_ylabel('Freqs in Hz')\n",
    "    ax2.plot(freq_arr)\n",
    "    #ax2.stem(freq_arr[2300:2400])\n",
    "    \n",
    "    ax3 = fig.add_subplot(313)\n",
    "    ax3.grid(b = True, axis = 'both', color = 'w', linestyle = '-', linewidth = 0.3)\n",
    "    ax3.set_title('Essentia pitch reference of ' + filename)\n",
    "    ax3.set_ylabel('Freqs in Hz')\n",
    "    ax3.set_xlabel('Frames')\n",
    "    ax3.plot(pitch)\n",
    "    #ax3.stem(pitch[2300:2400])\n",
    "    \n",
    "    return freq_arr\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the Multi-Pitch Trajectory (MPTC) algorithm\n",
    "freq_arr = mptc(audio_multi_pitch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trajectory Segmentation\n",
    "<a id=\"trajectory_segmentation\"></a>\n",
    "\n",
    "- Creating a set of different masks that decide whether the main pitch line is playing or not\n",
    "- Right now, the masks that have been applied are: \n",
    "    - Energy envelope per frame\n",
    "    - Frequency (un-quantised midi values for linearity of the system) derivative per frame\n",
    "- Mask the frequency array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_energy_mask(audio, energy_threshold = 0.1, frameSize = ANALYZE_SOUND_FRAME_SIZE, hopSize = HOP_SIZE):\n",
    "    '''Computes the energy per frame of the signal and generates a mask array for the given signal\n",
    "    Parameters\n",
    "    ----------\n",
    "    signal : numpy.array\n",
    "        Audio file\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    frame_freq : numpy.array\n",
    "        List of sorted frequencies by relevance for each frame\n",
    "    ''' \n",
    "    \n",
    "    # Getting the window\n",
    "    window = estd.Windowing()\n",
    "    \n",
    "    # Energy array\n",
    "    energy = []\n",
    "    \n",
    "    # For each frame in the audio file\n",
    "    for frame in estd.FrameGenerator(audio, frameSize = frameSize, hopSize = hopSize):\n",
    "\n",
    "        frame_win = window(frame)\n",
    "\n",
    "        energy.append(np.sum(frame_win**2) / len(frame))\n",
    "\n",
    "    energy = np.array(energy)\n",
    "\n",
    "    energy = np.convolve(energy, signal.get_window('triang',50), mode = 'same')\n",
    "\n",
    "    energy = energy / np.max(energy)\n",
    "    \n",
    "    # Computing the energy mask\n",
    "    energy[energy < energy_threshold] = 0\n",
    "    energy[energy >= energy_threshold] = 1\n",
    "    \n",
    "    # Returning the energy mask\n",
    "    return energy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_freq_diff_mask(freq_arr):\n",
    "    '''Computes the frequency derivative of a frequency array and generates a mask array for the given signal\n",
    "    Parameters\n",
    "    ----------\n",
    "    freq_arr : numpy.array\n",
    "        Frequency array\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    midi_diff_val_mask : numpy.array\n",
    "        Frequency derivative mask\n",
    "    ''' \n",
    "    \n",
    "    freq_arr = np.array(freq_arr)\n",
    "    midi_val = np.log2(freq_arr/440.0) * 12 + 69\n",
    "\n",
    "    midi_th = 0.2\n",
    "\n",
    "    midi_diff = abs(np.diff(midi_val))\n",
    "    midi_diff = np.append(midi_diff,0)\n",
    "\n",
    "    midi_diff = midi_diff / np.max(midi_diff)\n",
    "\n",
    "    midi_diff_mask = midi_diff.copy()\n",
    "\n",
    "    midi_diff_mask[midi_diff_mask < midi_th] = 0\n",
    "    midi_diff_mask[midi_diff_mask >= midi_th] = 1\n",
    "\n",
    "    midi_diff_val_mask = np.convolve(midi_diff_mask, signal.get_window('hann',60), mode = 'same')\n",
    "\n",
    "    midi_diff_val_mask = midi_diff_val_mask / np.max(midi_diff_val_mask)\n",
    "\n",
    "    midi_diff_val_mask[midi_diff_val_mask < midi_th] = 0\n",
    "    midi_diff_val_mask[midi_diff_val_mask >= midi_th] = 1\n",
    "\n",
    "    midi_diff_val_mask = 1 - midi_diff_val_mask\n",
    "              \n",
    "    # Returning the frequency derivative mask\n",
    "    return midi_diff_val_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trajectory_segmentation(audio, freq_arr, frameSize = ANALYZE_SOUND_FRAME_SIZE, hopSize = HOP_SIZE):\n",
    "    '''Computes the trakectory segmentation algorithm for the given signal\n",
    "    Parameters\n",
    "    ----------\n",
    "    audio : numpy.array\n",
    "        Audio file\n",
    "        \n",
    "    freq_arr : numpy.array\n",
    "        Array of the most likely frequency for each frame\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    frame_freq : numpy.array\n",
    "        List of sorted frequencies by relevance for each frame\n",
    "    ''' \n",
    "    \n",
    "    # Computing the energy mask\n",
    "    energy_mask = compute_energy_mask(audio)\n",
    "    \n",
    "    # Computing the frequency derivative mask\n",
    "    freq_diff_mask = compute_freq_diff_mask(freq_arr)\n",
    "    \n",
    "    # Applying the masks to the frequency array\n",
    "    freq_arr_masked = freq_arr * energy_mask * freq_diff_mask\n",
    "    \n",
    "    # Returning the masked frequency array\n",
    "    return freq_arr_masked, energy_mask, freq_diff_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the Trajectory Segmentation algorithm\n",
    "freq_arr_masked, energy_mask, freq_diff_mask = trajectory_segmentation(audio, freq_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing the results\n",
    "<a id=\"showing_results\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plotting the energy mask\n",
    "fig = plt.figure(figsize=(14, 20))\n",
    "ax1 = fig.add_subplot(511)\n",
    "ax1.grid(b = True, axis = 'both', color = 'w', linestyle = '-', linewidth = 0.3)\n",
    "ax1.set_title('Energy mask')\n",
    "ax1.set_ylabel('Freqs in Hz')\n",
    "ax1.plot(freq_arr)\n",
    "ax1.plot(energy_mask * np.max(freq_arr))\n",
    "\n",
    "# Plotting the derivative mask\n",
    "ax2 = fig.add_subplot(512)\n",
    "ax2.grid(b = True, axis = 'both', color = 'w', linestyle = '-', linewidth = 0.3)\n",
    "ax2.set_title('Derivative mask')\n",
    "ax2.set_ylabel('Freqs in Hz')\n",
    "ax2.plot(freq_arr)\n",
    "ax2.plot(freq_diff_mask * np.max(freq_arr), 'r')\n",
    "\n",
    "# Plotting the full\n",
    "ax3 = fig.add_subplot(513)\n",
    "ax3.grid(b = True, axis = 'both', color = 'w', linestyle = '-', linewidth = 0.3)\n",
    "ax3.set_title('Full mask')\n",
    "ax3.set_ylabel('Freqs in Hz')\n",
    "ax3.plot(freq_arr)\n",
    "ax3.plot(energy_mask * freq_diff_mask * np.max(freq_arr), 'g')\n",
    "\n",
    "# Plotting the masked pitch\n",
    "ax4 = fig.add_subplot(514)\n",
    "ax4.grid(b = True, axis = 'both', color = 'w', linestyle = '-', linewidth = 0.3)\n",
    "ax4.set_title('Masked pitch')\n",
    "ax4.set_ylabel('Freqs in Hz')\n",
    "ax4.plot(freq_arr)\n",
    "ax4.plot(freq_arr_masked, 'w')\n",
    "\n",
    "# Plotting the Essentia reference\n",
    "ax5 = fig.add_subplot(515)\n",
    "ax5.grid(b = True, axis = 'both', color = 'w', linestyle = '-', linewidth = 0.3)\n",
    "ax5.set_title('Essentia reference')\n",
    "ax5.set_ylabel('Freqs in Hz')\n",
    "ax5.set_xlabel('Frame')\n",
    "ax5.plot(pitch, 'm')\n",
    "\n",
    "# Saving the plots\n",
    "plt.savefig(OUTPUT_PLOT_FOLDER + \"/trajectory_segmentation.png\", transparent = True)\n",
    "\n",
    "# Showing the object to play the file\n",
    "ipd.display(ipd.Audio(audio, rate=44100))\n",
    "\n",
    "# Showing the plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(freq_arr_masked, 'w')\n",
    "plt.plot(pitch, 'm')\n",
    "plt.grid(b = True, axis = 'both', color = 'w', linestyle = '-', linewidth = 0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.grid(b = True, axis = 'both', color = 'w', linestyle = '-', linewidth = 0.3)\n",
    "plt.plot(abs(pitch-freq_arr_masked))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
